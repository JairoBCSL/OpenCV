= Programas de PDI

== 2. Manipulação de pixels de uma imagem

=== 2.2. Exercício

==== 2.2.1. Regions.cpp

Esse exercício consiste em tornar negativa uma região definida como parâmetro de uma imagem de entrada também fornecida como parâmetro. O exemplo usou a image do link:/OpenCV/imagens/biel.png[*_Biel_*] e os vértices opostos (100,100) e (200,200) que formarão a região retangular a ser negativada.

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/regions.cpp[regions.cpp]

[source,cpp]
----
//make regions
//./regions nome_imagem xmin ymin xmax ymax
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;

int main(int argc, char** argv){
  Mat image;
  int xmin, ymin, xmax, ymax;

  CvPoint p;
  image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  if(!image.data){
    std::cout << "imagem nao carregou corretamente\n";
    return(-1);
  }
  xmin = atoi(argv[2]);
  ymin = atoi(argv[3]);
  xmax = atoi(argv[4]);
  ymax = atoi(argv[5]);
  
  if(xmin<0||xmax>image.size().width||ymin<0||ymax>image.size().height||xmax<xmin||ymax<ymin){
    std::cout << "Parâmetros inválidos, escolha pontos dentro da largura da imagem\n";
    return 0;
  }

  for(int i=xmin; i<xmax; i++){
    for(int j=ymin; j<ymax; j++){
      image.at<uchar>(i,j)=(unsigned char)(256-(int)image.at<uchar>(i,j));
    }
  }

  imshow("Processada", image);
  imwrite("negativo.png", image);
  
  waitKey();
  return 0;
}
----

E os comandos a serem usados para compilar e executar o exemplo podem ser vistos abaixo

```markdown
make regions
./regions biel.png 100 100 200 200
```
Usando como imagem de entrada o link:/OpenCV/imagens/biel.png[*_Biel_*]

image:/OpenCV/imagens/biel.png[Biel]

e executando o programa, obtemos a imagem link:/OpenCV/imagens/negativo.png[*_Negativo_*] abaixo

image:/OpenCV/imagens/negativo.png[Negativo]

Para entender o código vamos observa-lo por parte:
O código possui uma parte onde inicializamos as variáveis a serem usadas, tenta abrir o arquivo de imagem e verifica se foi aberto com sucesso.

[source,cpp]
----
  Mat image;
  int xmin, ymin, xmax, ymax;

  CvPoint p;
  image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  if(!image.data){
    std::cout << "imagem nao carregou corretamente\n";
    return(-1);
  }
----

Após isso ele instancia as coordenadas dos vértices que definem o retângulo a ser negativado.

[source,cpp]
----
  xmin = atoi(argv[2]);
  ymin = atoi(argv[3]);
  xmax = atoi(argv[4]);
  ymax = atoi(argv[5]);
----

E então ele verifica a validade das coordenadas escolhidas

[source,cpp]
----
  if(xmin<0||xmax>image.size().width||ymin<0||ymax>image.size().height||xmax<xmin||ymax<ymin){
    std::cout << "Parâmetros inválidos, escolha pontos dentro da largura da imagem\n";
    return 0;
  }
----

E por fim, nesse trecho ele executa a negação para imprimir e salvar a imagem com a área negativada.

[source,cpp]
----
  for(int i=xmin; i<xmax; i++){
    for(int j=ymin; j<ymax; j++){
      image.at<uchar>(i,j)=(unsigned char)(256-(int)image.at<uchar>(i,j));
    }
  }
  
  imshow("Processada", image);
  imwrite("negativo.png", image);
----

==== 2.2.1. Trocaregioes.cpp

Esse exercício consiste em trocar os quadrantes de uma imagem de entrada fornecida como parâmetro. O exemplo usou a image do link:/OpenCV/imagens/biel.png[*_Biel_*] e o centro da imagem para trocar os quatro quadrantes.

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/trocaregioes.cpp[trocaregioes.cpp]

[source,cpp]
----
//	make trocaregioes
//	./trocaregioes nome_da_imagem
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image, save;
  int largura, altura;
  CvPoint p;
  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  save = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  if(!image.data||!save.data){
    cout << "Não carregou\n";
  }
  largura=image.size().width;
  altura=image.size().height;

  p.x=0;
  p.y=0;
  
  for(int i=0; i<altura; i++){
    for(int j=0; j<largura; j++){
      image.at<uchar>(i,j) = save.at<uchar>((i+altura/2)%altura,(j+largura/2)%largura);
    }
  }

  imshow("Original", save);  
  imshow("Processada", image);
  imwrite("trocada.png", image);
  waitKey();
  return 0;
}
----

E os comandos a serem usados para compilar e executar o exemplo podem ser vistos abaixo

```markdown
make trocaregioes
./trocaregioes biel.png
```
Usando como imagem de entrada o link:/OpenCV/imagens/biel.png[*_Biel_*]

image:/OpenCV/imagens/biel.png[Biel]

e executando o programa, obtemos a imagem link:/OpenCV/imagens/trocada.png[*_Trocada_*] abaixo

image:/OpenCV/imagens/trocada.png[Trocada]

Para entender o código vamos observa-lo por parte:
O código possui uma parte onde inicializamos as variáveis a serem usadas, tenta abrir o arquivo de imagem e verifica se foi aberto com sucesso.

[source,cpp]
----
  Mat image, save;
  int largura, altura;
  CvPoint p;
  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  save = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  if(!image.data||!save.data){
    cout << "Não carregou\n";
  }
----

Após isso ele obtém a largura e altura da imagem, e desloga os quadrantes da imagem

[source,cpp]
----
  largura=image.size().width;
  altura=image.size().height;

  p.x=0;
  p.y=0;
  
  for(int i=0; i<altura; i++){
    for(int j=0; j<largura; j++){
      image.at<uchar>(i,j) = save.at<uchar>((i+altura/2)%altura,(j+largura/2)%largura);
    }
  }

----

Ao fim ele exibe a imagem original e a trocada, e salva a imagem trocada.

[source,cpp]
----
  imshow("Original", save);  
  imshow("Processada", image);
  imwrite("trocada.png", image);
  }
----

== 3. Preenchimento de Regiões

=== 3.2. Exercício

==== 3.2.1 Labeling.cpp

Esse exercício consiste na contagem de bolhas com furos que não estão nas bordas da imagem. O número de bolhas e bolhas com furos é exibido no terminal e o bolhas com mais de um furo são contadas como somente uma bolha com furo. O exemplo usou as imagens link:/OpenCV/imagens/bolhas.png[*_Bolhas_*] que contém 32 bolhas e 7 com furos e link:/OpenCV/imagens/furos.png[*_Furos_*] com 262 bolhas sendo 8 com furos para conta-las.

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/labeling.cpp[labeling.cpp]

[source,cpp]
----
//make labeling
//./labeling bolhas.png
#include <iostream>
#include <opencv2/opencv.hpp>
using namespace cv;

//saturação => direção da luz;

int main(int argc, char** argv){
  Mat image, save;
  int width, height;
  int nobjects, fundo, furo;

  CvPoint p;
  image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  save = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  if(!image.data||!save.data){
    std::cout << "imagem nao carregou corretamente\n";
    return(-1);
  }
  width=image.size().width;
  height=image.size().height;

  p.x=0;
  p.y=0;

  // busca objetos presentes
  nobjects=0;
  furo=0;
  //std::cout << (int)image.at<uchar>(0,width-1) << std::endl;
  for(int i=0; i<height; i++){
    for(int j=0; j<width; j++){
      if(image.at<uchar>(i,j) == 255){//############
		// achou um objeto
		//std::cout << image.at<int>(i,j) << std::endl;
		nobjects++;
		p.x=j;
		p.y=i;
		floodFill(image,p,(nobjects%254));
      }
    }
  }
  fundo=254;
  printf("Tem %d bolhas\n", nobjects);

  // eliminando as bolhas da borda de cima
  p.y=0;
  for(int i=0; i<width; i++){
    if(image.at<uchar>(p.y,i) != 0){ //###############
      nobjects--;
      p.x=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
  // eliminando as bolhas da borda de baixo
  p.y=height-1;
  for(int i=0; i<width; i++){
    if(image.at<uchar>(p.y,i) != 0){//#############
      nobjects--;
      p.x=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
  // eliminando as bolhas da borda da esquerda
  p.x=0;
  for(int i=0; i<height; i++){
    if(image.at<uchar>(i,p.x) != 0){//##########
      nobjects--;
      p.y=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
  // eliminando as bolhas da borda da direita
  p.x=width-1;
  for(int i=0; i<height; i++){
    if(image.at<uchar>(i,p.x) != 0){//#############
      nobjects--;
      p.y=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);

  //achando buracos
  p.x=0;p.y=0;
  floodFill(image,p,fundo);
  for(int i=0; i<height; i++){
    for(int j=0; j<width; j++){
      if(image.at<uchar>(i,j) == 0){//############
	if(image.at<uchar>(i-1,j) !=fundo){//##########
	  furo++;
	  p.x=j;
	  p.y=i;
	  floodFill(image,p,fundo);
	  p.x--;
	  floodFill(image,p,fundo);
	}
	else{
	  p.x=j;
	  p.y=i;
	  floodFill(image,p,fundo);
	}
      }
    }
  }
  printf("Tem %d bolhas com buracos\n", furo);

  // exibindo
  imshow("Original", save);
  imshow("Processada", image);
  imwrite("labeling.png", image);
  
  waitKey();
  return 0;
}
----

Para compilar e executar o programa usamos os comandos abaixo substituindo imagem.png pelo nome da imagem em que serão procurados as bolhas e os furos.

```markdown
make labeling
./labeling imagem.png
```

Executando o programa com link:/OpenCV/imagens/bolhas.png[Bolhas] temos o seguinte resultado:

image:/OpenCV/imagens/bolhas.png[Bolhas]

e o resultado obtido é link:imagens/bolhas_labeling.png[Bolhas Labeling]

image:/OpenCV/imagens/bolhas_labeling.png[Bolhas Labeling]

E executando o programa com link:/OpenCV/imagens/furos.png[Furos] temos o seguinte resultado:

image:/OpenCV/imagens/furos.png[Furos]

e como resultado obtemos link:imagens/furos_labeling.png[Furos Labeling]

image:/OpenCV/imagens/furos_labeling.png[Furos Labeling]

O programa se divide em inicialização das variáveis

[source,cpp]
----
  Mat image, save;
  int width, height;
  int nobjects, fundo, furo;

  CvPoint p;
  image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  save = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);
  if(!image.data||!save.data){
    std::cout << "imagem nao carregou corretamente\n";
    return(-1);
  }
  width=image.size().width;
  height=image.size().height;

  p.x=0;
  p.y=0;
  nobjects=0;
  furo=0;
----

e em seguida o programa procura as bolhas.
 
[source,cpp]
----
for(int i=0; i<height; i++){
  for(int j=0; j<width; j++){
    if(image.at<uchar>(i,j) == 255){//############
      // achou um objeto
      //std::cout << image.at<int>(i,j) << std::endl;
      nobjects++;
      p.x=j;
      p.y=i;
      floodFill(image,p,(nobjects%254));
    }
  }
}
fundo=254;
----

Para contar as bolhas, o programa consigera que o fundo tem cor 0 (preto) e procura as bolhas com cor branca. Ao achar uma bolha, o número de objetos é incrementado e a bolha encontrada é pintada da cor correspondente na escala de cinza. Ao final o a cor de fundo é definida como 254, que é o nível que as bolhas não são pintadas.

.Depois da contagem de bolhas, as bolhas das bordas são eliminadas, pois não podemos afirmar se possuem furos ou se são bolhas que aparecem em mais de uma parte da borda.

[source,cpp]
----
p.y=0;
  for(int i=0; i<width; i++){
    if(image.at<uchar>(p.y,i) != 0){ //###############
      nobjects--;
      p.x=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
  // eliminando as bolhas da borda de baixo
  p.y=height-1;
  for(int i=0; i<width; i++){
    if(image.at<uchar>(p.y,i) != 0){//#############
      nobjects--;
      p.x=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
  // eliminando as bolhas da borda da esquerda
  p.x=0;
  for(int i=0; i<height; i++){
    if(image.at<uchar>(i,p.x) != 0){//##########
      nobjects--;
      p.y=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
  // eliminando as bolhas da borda da direita
  p.x=width-1;
  for(int i=0; i<height; i++){
    if(image.at<uchar>(i,p.x) != 0){//#############
      nobjects--;
      p.y=i;
      floodFill(image,p,0);
    }
  }
  //printf("Agora tem %d objetos\n", nobjects);
----

Por fim contamos o número de bolhas com furos através das verificaçes abaixo

[source,cpp]
----
p.x=0;p.y=0;
  floodFill(image,p,fundo);
  for(int i=0; i<height; i++){
    for(int j=0; j<width; j++){
      if(image.at<uchar>(i,j) == 0){//############
	if(image.at<uchar>(i-1,j) !=fundo){//##########
	  furo++;
	  p.x=j;
	  p.y=i;
	  floodFill(image,p,fundo);
	  p.x--;
	  floodFill(image,p,fundo);
	}
	else{
	  p.x=j;
	  p.y=i;
	  floodFill(image,p,fundo);
	}
      }
    }
  }
----

Visto que o fundo da imagem foi pintado no começo do programa, os furos podem ser achados se procurarmos pixels pretos. 

[source,cpp]
----
if(image.at<uchar>(i,j) == 0){
----

Ao encontrar um pixels preto, é verificado se seu pixel anterior tem cor diferente da cor de fundo, se sim, ele é o primeiro pixel do furos de alguma bolha, senão, ele é uma bolha que recebeu o valor 0 durante a contagem.

[source,cpp]
----
if(image.at<uchar>(i-1,j) !=fundo){//##########
  furo++;
  p.x=j;
  p.y=i;
  floodFill(image,p,fundo);
  p.x--;
  floodFill(image,p,fundo);
}
else{
  p.x=j;
  p.y=i;
  floodFill(image,p,fundo);
}
----

== 4. Histogramas

=== 4.2. Exercício

==== 4.2.1. Equalize.cpp

Esse exercício vai se propor a equalizar o histograma de uma imagem afim de torna-lo mais destribuído entre os tons de RGB. Os exemplos usados serão link:/OpenCV/imagens/cachorro.png e link:/OpenCV/imagens/nissan.png e retornarão imagens com o histograma equalizado. Lembrando que a operação de equalização de histograma não retorna obrigatoriamente um resultado melhor que a imagem de entrada, pois algumas imagens precisão de um espaço grande entre os tons ou até tons próximos para que o olho considere mais agradáveis.

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/equalize.cpp[equalize.cpp]

[source,cpp]
----
//make equalize
//./equalize imagem.extensão
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image, sv;
  vector<Mat> planes, svPlanes;
  Mat histR, histG, histB;
  Mat histRs, histGs, histBs;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgRs(histh, histw, CV_8UC3, Scalar(0,0,0));//#
  Mat histImgGs(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgBs(histh, histw, CV_8UC3, Scalar(0,0,0));

    image = imread(argv[1], CV_LOAD_IMAGE_COLOR);

    split (image, planes);
    image.copyTo(sv);
    split (sv, svPlanes);

    equalizeHist(svPlanes[0], svPlanes[0]);//#
    equalizeHist(svPlanes[1], svPlanes[1]);
    equalizeHist(svPlanes[2], svPlanes[2]);

    calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[1], 1, 0, Mat(), histG, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[2], 1, 0, Mat(), histB, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&svPlanes[0], 1, 0, Mat(), histRs, 1,//#
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&svPlanes[1], 1, 0, Mat(), histGs, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&svPlanes[2], 1, 0, Mat(), histBs, 1,
             &nbins, &histrange,
             uniform, acummulate);

    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
    normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
    normalize(histRs, histRs, 0, histImgRs.rows, NORM_MINMAX, -1, Mat());//#
    normalize(histGs, histGs, 0, histImgGs.rows, NORM_MINMAX, -1, Mat());
    normalize(histBs, histBs, 0, histImgBs.rows, NORM_MINMAX, -1, Mat());

    histImgR.setTo(Scalar(0));
    histImgG.setTo(Scalar(0));
    histImgB.setTo(Scalar(0));
    histImgRs.setTo(Scalar(0));//#
    histImgGs.setTo(Scalar(0));
    histImgBs.setTo(Scalar(0));
    
    for(int i=0; i<nbins; i++){
      line(histImgR,
           Point(i, histh),
           Point(i, histh-cvRound(histR.at<float>(i))),
           Scalar(0, 0, 255), 1, 8, 0);
      line(histImgG,
           Point(i, histh),
           Point(i, histh-cvRound(histG.at<float>(i))),
           Scalar(0, 255, 0), 1, 8, 0);
      line(histImgB,
           Point(i, histh),
           Point(i, histh-cvRound(histB.at<float>(i))),
           Scalar(255, 0, 0), 1, 8, 0);
      line(histImgRs,
           Point(i, histh),
           Point(i, histh-cvRound(histRs.at<float>(i))),
           Scalar(0, 0, 255), 1, 8, 0);//#
      line(histImgGs,
           Point(i, histh),
           Point(i, histh-cvRound(histGs.at<float>(i))),
           Scalar(0, 255, 0), 1, 8, 0);
      line(histImgBs,
           Point(i, histh),
           Point(i, histh-cvRound(histBs.at<float>(i))),
           Scalar(255, 0, 0), 1, 8, 0);
    }

    merge(svPlanes, sv);

    histImgR.copyTo(image(Rect(0, 0      , nbins, histh)));
    histImgG.copyTo(image(Rect(0, histh  , nbins, histh)));
    histImgB.copyTo(image(Rect(0, 2*histh, nbins, histh)));
    histImgRs.copyTo(sv(Rect(0, 0      , nbins, histh)));
    histImgGs.copyTo(sv(Rect(0, histh  , nbins, histh)));
    histImgBs.copyTo(sv(Rect(0, 2*histh, nbins, histh)));
    imshow("image", image);
    imshow("sv", sv);
    imwrite("imagem.png", sv);
    if(waitKey(-1));

  return 0;
}
----

Para compilar e executar o programa usamos os comandos abaixo substituindo imagem.png pelo nome da imagem que terá o histograma equalizado

```markdown
make equalize
./equalize imagem.extensão
```

Usando como imagem de entrada o link:/OpenCV/imagens/cachorro.jpeg[*_Catiolo_*]

image:/OpenCV/imagens/cachorro.jpeg[Cachorro]

e executando o programa, obtemos uma imagem equalizada mais realista link:/OpenCV/imagens/cachorroeq.png[*_Cariolo Equalizado_*]

image:/OpenCV/imagens/cachorroeq.png[Cachorro Equalizada]

Usando como imagem de entrada o link:/OpenCV/imagens/carro.jpg[*_Carrão_*]

image:/OpenCV/imagens/carro.jpg[Carro]

e executando o programa, obtemos uma imagem equalizada não tão agradável chegando até a mudar a cor do carro link:/OpenCV/imagens/carroeq.png[*_Carrão Equalizado_*]

image:/OpenCV/imagens/carroeq.png[Cachorro Equalizada]

O programa se inicia com as declarações de histogramas e imagens junto com a cópia da imagem para fins de comparação, depois disso a imagem é separada nos canais RGB

[source,cpp]
----
  Mat image, sv;
  vector<Mat> planes, svPlanes;
  Mat histR, histG, histB;
  Mat histRs, histGs, histBs;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgRs(histh, histw, CV_8UC3, Scalar(0,0,0));//#
  Mat histImgGs(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgBs(histh, histw, CV_8UC3, Scalar(0,0,0));
  
  image = imread(argv[1], CV_LOAD_IMAGE_COLOR);
  
  split (image, planes);
  image.copyTo(sv);
  split (sv, svPlanes);
----

e em seguida o programa realiza a equalização do histograma da imagem e o calculo dos histogramas da imagem equalizada e da original, seguidos pela normalização e criação da imagem dos histogramas
 
[source,cpp]
----
  equalizeHist(svPlanes[0], svPlanes[0]);
  equalizeHist(svPlanes[1], svPlanes[1]);
  equalizeHist(svPlanes[2], svPlanes[2]);

  calcHist(&planes[0], 1, 0, Mat(), histR, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&planes[1], 1, 0, Mat(), histG, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&planes[2], 1, 0, Mat(), histB, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&svPlanes[0], 1, 0, Mat(), histRs, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&svPlanes[1], 1, 0, Mat(), histGs, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&svPlanes[2], 1, 0, Mat(), histBs, 1, &nbins, &histrange, uniform, acummulate);
  
  normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
  normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
  normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
  normalize(histRs, histRs, 0, histImgRs.rows, NORM_MINMAX, -1, Mat());
  normalize(histGs, histGs, 0, histImgGs.rows, NORM_MINMAX, -1, Mat());
  normalize(histBs, histBs, 0, histImgBs.rows, NORM_MINMAX, -1, Mat());

  histImgR.setTo(Scalar(0));
  histImgG.setTo(Scalar(0));
  histImgB.setTo(Scalar(0));
  histImgRs.setTo(Scalar(0));
  histImgGs.setTo(Scalar(0));
  histImgBs.setTo(Scalar(0));
----

Por fim, os histogramas são desenhados e copiados para dentro da imagem

[source,cpp]
----
  for(int i=0; i<nbins; i++){
    line(histImgR, Point(i, histh), Point(i, histh-cvRound(histR.at<float>(i))),
         Scalar(0, 0, 255), 1, 8, 0);
    line(histImgG, Point(i, histh), Point(i, histh-cvRound(histG.at<float>(i))),
         Scalar(0, 255, 0), 1, 8, 0);
    line(histImgB, Point(i, histh), Point(i, histh-cvRound(histB.at<float>(i))),
         Scalar(255, 0, 0), 1, 8, 0);
    line(histImgRs, Point(i, histh), Point(i, histh-cvRound(histRs.at<float>(i))),
         Scalar(0, 0, 255), 1, 8, 0);
    line(histImgGs, Point(i, histh), Point(i, histh-cvRound(histGs.at<float>(i))),
         Scalar(0, 255, 0), 1, 8, 0);
    line(histImgBs, Point(i, histh), Point(i, histh-cvRound(histBs.at<float>(i))),
         Scalar(255, 0, 0), 1, 8, 0);
  }

  merge(svPlanes, sv);

  histImgR.copyTo(image(Rect(0, 0      , nbins, histh)));
  histImgG.copyTo(image(Rect(0, histh  , nbins, histh)));
  histImgB.copyTo(image(Rect(0, 2*histh, nbins, histh)));
  histImgRs.copyTo(sv(Rect(0, 0      , nbins, histh)));
  histImgGs.copyTo(sv(Rect(0, histh  , nbins, histh)));
  histImgBs.copyTo(sv(Rect(0, 2*histh, nbins, histh)));
----

==== 4.2.1. Equalize.cpp

Esse programa se propõe a detectar movimentos na câmera a partir de alterações no histograma da imagem.

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/motiondetector.cpp[motiondetector.cpp]

[source,cpp]
----

//make motiondetector
//./motiondetector
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;
  int width, height, al = 0;
  VideoCapture cap;
  vector<Mat> planes;
  Mat histR, histG, histB;
  Mat histRs, histGs, histBs;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  cap.open(0);
  
  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }

  for(int i=0; i<30; i++)
    cap >> image;

  int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));

  split(image, planes);
  calcHist(&planes[0], 1, 0, Mat(), histR, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&planes[1], 1, 0, Mat(), histG, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&planes[2], 1, 0, Mat(), histB, 1, &nbins, &histrange, uniform, acummulate);
  normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
  normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
  normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
  histR.copyTo(histRs);
  histG.copyTo(histGs);
  histB.copyTo(histBs);

  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;



  while(1){
    cap >> image;
    split (image, planes);
    calcHist(&planes[0], 1, 0, Mat(), histR, 1, &nbins, &histrange, uniform, acummulate);
    calcHist(&planes[1], 1, 0, Mat(), histG, 1, &nbins, &histrange, uniform, acummulate);
    calcHist(&planes[2], 1, 0, Mat(), histB, 1, &nbins, &histrange, uniform, acummulate);

    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
    normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());

    histImgR.setTo(Scalar(0));
    histImgG.setTo(Scalar(0));
    histImgB.setTo(Scalar(0));
    
    for(int i=0; i<nbins; i++){
      line(histImgR,
           Point(i, histh),
           Point(i, histh-cvRound(histR.at<float>(i))),
           Scalar(0, 0, 255), 1, 8, 0);
      line(histImgG,
           Point(i, histh),
           Point(i, histh-cvRound(histG.at<float>(i))),
           Scalar(0, 255, 0), 1, 8, 0);
      line(histImgB,
           Point(i, histh),
           Point(i, histh-cvRound(histB.at<float>(i))),
           Scalar(255, 0, 0), 1, 8, 0);
    }
    histImgR.copyTo(image(Rect(0, 0       ,nbins, histh)));
    histImgG.copyTo(image(Rect(0, histh   ,nbins, histh)));
    histImgB.copyTo(image(Rect(0, 2*histh ,nbins, histh)));

    if(compareHist(histR, histRs, CV_COMP_CORREL) < 0.98 || 
       compareHist(histG, histGs, CV_COMP_CORREL) < 0.98 || 
       compareHist(histB, histBs, CV_COMP_CORREL) < 0.98){
      cout << "Bang! " << ++al << endl;
      histR.copyTo(histRs);
      histG.copyTo(histGs);
      histB.copyTo(histBs);  


    }

    imshow("image", image);
    waitKey(42);
  }
  return 0;
}

----

Para compilar e executar o programa usamos os comandos abaixo substituindo imagem.png pelo nome da imagem que terá o histograma equalizado

```markdown
make motiondetector
./motiondetector
```

O programa avisa a detecção do movimento a partir do 'Bang' no terminal.

```markdown
largura = 848
altura  = 480
Bang! 1
Bang! 2
Bang! 3
Bang! 4
```

O programa começa com as declarações e inicializações necessárias tais como a criação dos histogramas em cada canal RGB no frame atual e no anterior, e o vetor de matrizes correspondente a cada canal.

[source,cpp]
----
  Mat image;
  int width, height, al = 0;
  VideoCapture cap;
  vector<Mat> planes;
  Mat histR, histG, histB;
  Mat histRs, histGs, histBs;
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
----

a partir daí, o programa cria as matrizes de imagem do histograma a serem calculados do primeiro frame, divide a imagem e 'planes' que são as matrizes dos canais RGB, calcula os histogramas, os normaliza e salva o primeiro histograma.
 
[source,cpp]
----
int histw = nbins, histh = nbins/2;
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));

  split(image, planes);
  calcHist(&planes[0], 1, 0, Mat(), histR, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&planes[1], 1, 0, Mat(), histG, 1, &nbins, &histrange, uniform, acummulate);
  calcHist(&planes[2], 1, 0, Mat(), histB, 1, &nbins, &histrange, uniform, acummulate);
  normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
  normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
  normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());
  histR.copyTo(histRs);
  histG.copyTo(histGs);
  histB.copyTo(histBs);
----

Depois ele entra num loop while(1) que captura um novo frame e calcula o histograma do novo frame, normaliza-o e cria a imagem dele.

[source,cpp]
----
cap >> image;
    split (image, planes);
    calcHist(&planes[0], 1, 0, Mat(), histR, 1, &nbins, &histrange, uniform, acummulate);
    calcHist(&planes[1], 1, 0, Mat(), histG, 1, &nbins, &histrange, uniform, acummulate);
    calcHist(&planes[2], 1, 0, Mat(), histB, 1, &nbins, &histrange, uniform, acummulate);

    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histG, histG, 0, histImgG.rows, NORM_MINMAX, -1, Mat());
    normalize(histB, histB, 0, histImgB.rows, NORM_MINMAX, -1, Mat());

    histImgR.setTo(Scalar(0));
    histImgG.setTo(Scalar(0));
    histImgB.setTo(Scalar(0));
----

Depois ele 'desenha' o histograma do frame atual e copia para a imagem.

[source,cpp]
----
    for(int i=0; i<nbins; i++){
      line(histImgR, Point(i, histh), Point(i, histh-cvRound(histR.at<float>(i))), Scalar(0, 0, 255), 1, 8, 0);
      line(histImgG, Point(i, histh), Point(i, histh-cvRound(histG.at<float>(i))), Scalar(0, 255, 0), 1, 8, 0);
      line(histImgB, Point(i, histh), Point(i, histh-cvRound(histB.at<float>(i))), Scalar(255, 0, 0), 1, 8, 0);
    }
    histImgR.copyTo(image(Rect(0, 0       ,nbins, histh)));
    histImgG.copyTo(image(Rect(0, histh   ,nbins, histh)));
    histImgB.copyTo(image(Rect(0, 2*histh ,nbins, histh)));
----

Por fim ele compara o novo histograma com o antigo e se a similaridade da comparação (correlação) for menor que 98% em algum canal, o movimento é avisado e o histograma atual passa a ser o salvo para a próxima comparação.

[source,cpp]
----
    if(compareHist(histR, histRs, CV_COMP_CORREL) < 0.98 || 
       compareHist(histG, histGs, CV_COMP_CORREL) < 0.98 || 
       compareHist(histB, histBs, CV_COMP_CORREL) < 0.98){
      cout << "Bang! " << ++al << endl;
      histR.copyTo(histRs);
      histG.copyTo(histGs);
      histB.copyTo(histBs);  
----

== 5. Filtragem Espacial I

=== 5.2. Exercício

==== 5.2.1. lapsgauss.cpp


Esse exercício consiste na aplicação do filtro de LoG ou laplaciano da gaussiana e comparação com a simples aplicação do laplaciano à um fluxo de câmera. Tomei a liberdade de mudar a máscara de laplaciano para ficar proporcional à máscara LoG em tamanho.

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/laplgauss.cpp[laplgauss.cpp]

[source,cpp]
----
//make laplgauss
//./laplgauss
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
    "m - media\n"
    "g - gaussiano\n"
    "v - vertical\n"
    "h - horizontal\n"
    "l - laplaciano\n"
    "c - laplaciano do gaussiano\n"
    "esc - sair\n";
}

int main(int argvc, char** argv){
  VideoCapture video;
  float media[] = {1,1,1,
                   1,1,1,
                   1,1,1};
  float gauss[] = {1,2,1,
                   2,4,2,
                   1,2,1};
  float horizontal[]={-1,0,1,
                      -2,0,2,
                      -1,0,1};
  float vertical[]={-1,-2,-1,
                      0,0,0,
                      1,2,1};
  float laplacian[]={-1,-1,-1,-1,-1,
                     -1,-1,-1,-1,-1,
                     -1,-1,24,-1,-1,
                     -1,-1,-1,-1,-1,
                     -1,-1,-1,-1,-1};

  float nda[]={0,0,0,
               0,1,0,
               0,0,0};

  float laplgauss[]={0, 0,-1, 0, 0,
                     0,-1,-2,-1, 0,
                    -1,-2,16,-2,-1,
                     0,-1,-2,-1, 0,
                     0, 0,-1, 0, 0 };


  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
  double width, height;
  int absolut;
  char key;
  
  video.open(0); 
  if(!video.isOpened()) 
    return -1;
  width=video.get(CV_CAP_PROP_FRAME_WIDTH);
  height=video.get(CV_CAP_PROP_FRAME_HEIGHT);
  std::cout << "largura=" << width << "\n";;
  std::cout << "altura =" << height<< "\n";;

  namedWindow("filtroespacial",1);

  mask = Mat(3, 3, CV_32F, media); 
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  swap(mask, mask1);
  absolut=1; // calcs abs of the image

  menu();
  for(;;){
    video >> cap; 
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
	  menu();
      absolut=!absolut;
      break;
    case 'm':
	  menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'g':
	  menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'h':
	  menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      break;
    case 'v':
	  menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      break;
    case 'l':
	  menu();
      mask = Mat(5, 5, CV_32F, laplacian);
      scaleAdd(mask, 1/8.0, Mat::zeros(5,5,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      imwrite("lapla.png", result);
      break;
    case 'c':
	  menu();

      mask = Mat(5, 5, CV_32F, laplgauss);
      scaleAdd(mask, 1/4.0, Mat::zeros(5,5,CV_32F), mask1);
      mask = mask1;

      imwrite("log.png", result);
      printmask(mask);
      break;
    case 'n':
	  menu();
      mask = Mat(3, 3, CV_32F, nda);
      printmask(mask);
      break;

    default:
      break;
    }
    filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
    if(absolut){
      frameFiltered=abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);
    imshow("filtroespacial", result);

  }
  imwrite("normal.png", frame);
  return 0;
}
----

E os comandos a serem usados para compilar e executar o exemplo podem ser vistos abaixo

```markdown
make laplgauss
./laplgauss
```
Executando o programa, um frame inalterado é salvo link:/OpenCV/imagens/normal.png[*_Normal_*]

image:/OpenCV/imagens/normal.png[Normal]

uma imagem aplicada o filtro laplaciano link:/OpenCV/imagens/lapla.png[*_Laplaciano_*]

image:/OpenCV/imagens/lapla.png[Laplaciano]

uma imagem aplicada o filtro LoG link:/OpenCV/imagens/log.png[*_LoG_*] abaixo

image:/OpenCV/imagens/log.png[Trocada]

Para entender o código vamos observa-lo por parte:
Inicialmente temos duas funções, uma que exibe o máscara sendo usada e outra que funciona como o menu do programa

[source,cpp]
----
void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
    "m - media\n"
    "g - gaussiano\n"
    "v - vertical\n"
    "h - horizontal\n"
    "l - laplaciano\n"
    "c - laplaciano do gaussiano\n"
    "esc - sair\n";
}
----

Após isso temos a criação das máscaras e das matrizes que guardarão as imagens em 0~255, float e a imagem filtrada, como também as matrizes resultado

[source,cpp]
----
VideoCapture video;
  float media[] = {1,1,1,
                   1,1,1,
                   1,1,1};
  float gauss[] = {1,2,1,
                   2,4,2,
                   1,2,1};
  float horizontal[]={-1,0,1,
                      -2,0,2,
                      -1,0,1};
  float vertical[]={-1,-2,-1,
                      0,0,0,
                      1,2,1};
  float laplacian[]={-1,-1,-1,-1,-1,
                     -1,-1,-1,-1,-1,
                     -1,-1,24,-1,-1,
                     -1,-1,-1,-1,-1,
                     -1,-1,-1,-1,-1};

  float nda[]={0,0,0,
               0,1,0,
               0,0,0};

  float laplgauss[]={0, 0,-1, 0, 0,
                     0,-1,-2,-1, 0,
                    -1,-2,16,-2,-1,
                     0,-1,-2,-1, 0,
                     0, 0,-1, 0, 0 };


  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
----

Após isso, o programa abre a câmera e aplica o filtro de média inicialmente

[source,cpp]
----
video.open(0); 
  if(!video.isOpened()) 
    return -1;
  width=video.get(CV_CAP_PROP_FRAME_WIDTH);
  height=video.get(CV_CAP_PROP_FRAME_HEIGHT);
  std::cout << "largura=" << width << "\n";;
  std::cout << "altura =" << height<< "\n";;

  namedWindow("filtroespacial",1);

  mask = Mat(3, 3, CV_32F, media); 
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  swap(mask, mask1);
  absolut=1; // calcs abs of the image
----

Nessa parte do programa, a função menu é chamada e o for, dependendo do filtro selecionado, o case aplica o filtro na imagem já adicionando as escalas, se necessário. E ao fim de cada aplicação do filtro, a função menu é chamada novamente.

[source,cpp]
----
menu();
  for(;;){
    video >> cap; 
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
	  menu();
      absolut=!absolut;
      break;
    case 'm':
	  menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'g':
	  menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      break;
    case 'h':
	  menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      break;
    case 'v':
	  menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      break;
    case 'l':
	  menu();
      mask = Mat(5, 5, CV_32F, laplacian);
      scaleAdd(mask, 1/8.0, Mat::zeros(5,5,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      imwrite("lapla.png", result);
      break;
    case 'c':
	  menu();

      mask = Mat(5, 5, CV_32F, laplgauss);
      scaleAdd(mask, 1/4.0, Mat::zeros(5,5,CV_32F), mask1);
      mask = mask1;

      imwrite("log.png", result);
      printmask(mask);
      break;
    case 'n':
	  menu();
      mask = Mat(3, 3, CV_32F, nda);
      printmask(mask);
      break;

    default:
      break;
    }
----

Por fim, aplica-se o absoluto, se estiver ativo, e a imagem é salva.

[source,cpp]
----
    filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
    if(absolut){
      frameFiltered=abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);
    imshow("filtroespacial", result);

  }
  imwrite("normal.png", frame);
  return 0;
----

Comparando as imagens obtidas com os filtros laplaciano e LoG podemos notar uma melhor percepção das bordas e menos ruído na imagem filtrada com o LoG quando comparada com a imagem filtrada com o filtro laplaciano.

== 7. Filtragem no domínio da frequência

=== 7.1. Exercício

==== 7.1.1. HMorfico.cpp

Esse exercício pretende explorar a filtragem de imagem no domínio da frequência usando um tipo de filtro chamado homomórfico para ajudar a reduzir algum problema de iluminação. Para tal experimento será usada a imagem link:/OpenCV/imagens/nissan.jpg[*_Nissan_*]

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/hmorfico.cpp[hmorfico.cpp]

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui.hpp>
#include <conio.h>

using namespace cv;
using namespace std;

double gi = 0.0, gs = 1, c = 1, d0 = 2;
char key;
Mat imagem, filtro;
vector<Mat> planos;
void troca(Mat& imagem);
void menu();

int main(int argc, char** argv) {
	Mat original, imagemRe, imagemIm, imagemComp;
	Mat filtroComp;
	int largura, altura;



	original = imread("nissan.jpg", CV_LOAD_IMAGE_GRAYSCALE);
	largura = getOptimalDFTSize(original.cols);
	altura = getOptimalDFTSize(original.rows);
	copyMakeBorder(original, imagem, 0, largura - original.cols, 0, altura - original.rows, BORDER_CONSTANT, Scalar(0, 0, 0));

	imagemIm = Mat_<float>::zeros(imagem.size());
	imagemComp = Mat(imagem.size(), CV_32FC2, Scalar(0));
	filtroComp = imagemComp.clone();
	filtro = Mat(altura, largura, CV_32F);

	for (;;) {
		for (int i = 0; i < largura; i++) {
			for (int j = 0; j < altura; j++) {
				filtro.at<float>(Point(i, j)) = (gs - gi) * (1 - exp(-c * (((i - largura / 2) * (i - largura / 2) + (j - altura / 2) * (j - altura / 2)) / (d0 * d0)))) + gi;
			}
		}

		Mat comps[] = { filtro, filtro };
		merge(comps, 2, filtroComp);

		planos.clear();
		imagemRe = Mat_<float>(imagem);
		planos.push_back(imagemRe);
		planos.push_back(imagemIm);
		merge(planos, imagemComp);
		dft(imagemComp, imagemComp);
		troca(imagemComp);
		mulSpectrums(imagemComp, filtroComp, imagemComp, 0);
		planos.clear();
		troca(imagemComp);
		idft(imagemComp, imagemComp);
		planos.clear();
		split(imagemComp, planos);
		normalize(planos[0], planos[0], 0, 1, CV_MINMAX);

		//imshow("Ori", original);
		//waitKey();
		//imshow("Ima", planos[0]);
		//waitKey();
		//imshow("Fil", filtro);
		imshow("Original", imagem);
		imshow("Imagem", planos[0]);
		imshow("Filtro", filtro);
		menu();
	}

	return 0;
}

void troca(Mat& imagem) {
	Mat tmp, A, B, C, D;

	imagem = imagem(Rect(0, 0, imagem.cols & -2, imagem.rows & -2));
	int cx = imagem.cols / 2, cy = imagem.rows / 2;
	A = imagem(Rect(0, 0, cx, cy));
	B = imagem(Rect(cx, 0, cx, cy));
	C = imagem(Rect(0, cy, cx, cy));
	D = imagem(Rect(cx, cy, cx, cy));

	A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);
	C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);

}

void menu() {
	key = waitKey();
	switch (key) {
	case 'q':
		gi += 0.1;
		cout << "Gi: " << gi << endl;
		break;
	case 'a':
		gi -= 0.1;
		cout << "Gi: " << gi << endl;
		break;
	case 'w':
		gs += 0.1;
		cout << "Gs: " << gs << endl;
		break;
	case 's':
		gs -= 0.1;
		cout << "Gs: " << gs << endl;
		break;
	case 'e':
		c += 0.1;
		cout << "C:  " << c << endl;
		break;
	case 'd':
		c -= 0.1;
		cout << "C:  " << c << endl;
		break;
	case 'r':
		d0 += 0.1;
		cout << "D0: " << d0 << endl;
		break;
	case 'f':
		d0 -= 0.1;
		cout << "D0: " << d0 << endl;
		break;
	case 't':
		imwrite("originalHmorfico.png", imagem);
		imwrite("hmorfico.png", planos[0]*255);
		imwrite("filtroHmorfico.png", filtro*255);
		break;
	default:
		break;

	}
}
----

Para a compilação e execução foi usado o Visual Studio Comunity e os parâmetros de controle do filtro podem ser modificados usando o teclado durante a execução do programa

Usando como imagem de entrada o link:/OpenCV/imagens/nissan.jpg[*_Nissan_*]

image:/OpenCV/imagens/nissan.jpg[Nissan]

e executando o programa, obtemos a imagem link:/OpenCV/imagens/hmorfico.png[*_Homomórfico_*] abaixo

image:/OpenCV/imagens/hmorfico.png[Homomórfico]

usando o filtro link:/OpenCV/imagens/filtroHmorfico.png[*_FIltroHmorfico_*] abaixo

image:/OpenCV/imagens/filtroHmorfico.png[FiltroHmorfico]

Para entender o código vamos observa-lo por parte:
O código possui uma parte onde inicializamos as variáveis a serem usadas, tentamos abrir a imagem e obtemos as dimensões dela, como também fazemos a borda para otimizar a fft.

[source,cpp]
----
double gi = 0.0, gs = 1, c = 1, d0 = 2;
char key;
Mat imagem, filtro;
vector<Mat> planos;
void troca(Mat& imagem);
void menu();

int main(int argc, char** argv) {
   Mat original, imagemRe, imagemIm, imagemComp;
   Mat filtroComp;
   int largura, altura;
   original = imread("nissan.jpg", CV_LOAD_IMAGE_GRAYSCALE);
   largura = getOptimalDFTSize(original.cols);
   altura = getOptimalDFTSize(original.rows);
   copyMakeBorder(original, imagem, 0, largura - original.cols, 0, altura - original.rows, BORDER_CONSTANT, Scalar(0, 0, 0));
   imagemIm = Mat_<float>::zeros(imagem.size());
   imagemComp = Mat(imagem.size(), CV_32FC2, Scalar(0));
   filtroComp = imagemComp.clone();
   filtro = Mat(altura, largura, CV_32F);
----

Após isso, o loop começa e o filtro é criado. É necessário criar imagem complexas para a fft, onde unimos as componentes da imagem (real e imaginária) e aplicamos a multiplicação espectral, e em seguida a transformada inversa,a separação e a normalização da imagem.

[source,cpp]
----
for (;;) {
   for (int i = 0; i < largura; i++) {
      for (int j = 0; j < altura; j++) {
         filtro.at<float>(Point(i, j)) = (gs - gi) * (1 - exp(-c * (((i - largura / 2) * (i - largura / 2) + (j - altura / 2) * (j - altura / 2)) / (d0 * d0)))) + gi;
      }
   }

Mat comps[] = { filtro, filtro };
merge(comps, 2, filtroComp);

planos.clear();
imagemRe = Mat_<float>(imagem);
planos.push_back(imagemRe);
planos.push_back(imagemIm);
merge(planos, imagemComp);
dft(imagemComp, imagemComp);
troca(imagemComp);
mulSpectrums(imagemComp, filtroComp, imagemComp, 0);
planos.clear();
troca(imagemComp);
idft(imagemComp, imagemComp);
planos.clear();
split(imagemComp, planos);
normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
----

Uma função foi criada para trocar os quadrantes da imagem, para facilitar a visualização e aplicação do filtro.

[source,cpp]
----
void troca(Mat& imagem) {
   Mat tmp, A, B, C, D;

   imagem = imagem(Rect(0, 0, imagem.cols & -2, imagem.rows & -2));
   int cx = imagem.cols / 2, cy = imagem.rows / 2;
   A = imagem(Rect(0, 0, cx, cy));
   B = imagem(Rect(cx, 0, cx, cy));
   C = imagem(Rect(0, cy, cx, cy));
   D = imagem(Rect(cx, cy, cx, cy));

   A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);
   C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);

}
----















== 8. Detecção de bordas com Canny

=== 8.1. Exercício

==== 8.1.1. Cannypoints.cpp

Esse exercício pretende explorar a a detecção de bordas usando o algoritmo do canny e usa-lo em uma aplicação de arte chamada pontilhismo. Para o experimento usaremos a imagem link:/OpenCV/imagens/nissan.jpg[*_Nissan_*]

O código fonte do programa pode ser visto abaixo: link:/OpenCV/codes/cannypoints.cpp[cannypoints.cpp]

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <fstream>
#include <iomanip>
#include <vector>
#include <algorithm>
#include <numeric>
#include <ctime>
#include <cstdlib>

using namespace std;
using namespace cv;

int step_slider = 3, step_slider_max = 10;
int jitter_slider = 3, jitter_slider_max = 20;
int raio_slider = 3, raio_slider_max = 5;
int raio_edge = 2, raio_edge_max = 5;
int lowTH_slider = 200, lowTH_slider_max = 200;
int highTH_slider = 600, highTH_slider_max = 600;
char step_Track[10], jitter_Track[10], raio_Track[10];
char raioEdge_Track[10], lowTH_Track[10], highTH_Track[10];

Mat image, points, border, borderpoints, fim;

vector<int> yrange, xrange;

int width, height, gray;
int x, y;

void on_trackbar_pontos(int, void*) {
	Canny(image, border, lowTH_slider, highTH_slider);
	if (step_slider < 2) step_slider = 1;
	if (jitter_slider < 2) jitter_slider = 1;
	if (raio_slider < 2) raio_slider = 1;
	xrange.resize(height / step_slider);
	yrange.resize(width / step_slider);

	iota(xrange.begin(), xrange.end(), 0);
	iota(yrange.begin(), yrange.end(), 0);

	for (uint i = 0; i < xrange.size(); i++) {
		xrange[i] = xrange[i] * step_slider + step_slider / 2;
	}

	for (uint i = 0; i < yrange.size(); i++) {
		yrange[i] = yrange[i] * step_slider + step_slider / 2;
	}

	points = Mat(height, width, CV_8U, Scalar(255));

	random_shuffle(xrange.begin(), xrange.end());
	for (int i = 0; i < xrange.size(); i++) {
		random_shuffle(yrange.begin(), yrange.end());
		for (int j = 0; j < yrange.size(); j++) {
			x = xrange[i] + rand() % (2 * jitter_slider) - jitter_slider + 1;
			y = yrange[j] + rand() % (2 * jitter_slider) - jitter_slider + 1;
			if (x >= height) x = height - 1;
			if (y >= width) y = width - 1;
			if (x < 0) x = 0;
			if (y < 0) y = 0;
			gray = image.at<uchar>(x, y);
			circle(points, cv::Point(y, x), raio_slider, CV_RGB(gray, gray, gray), -1, CV_AA);
		}
	}

	borderpoints = Mat(height, width, CV_8U, Scalar(0));

	for (int x = 0; x < height; x++) {
		for (int y = 0; y < width; y++) {
			if (border.at<uchar>(x, y) == 255) {
				//if (25 > (rand() % 100)) {
					gray = image.at<uchar>(x, y);
					circle(borderpoints, cv::Point(y, x), raio_edge, CV_RGB(gray, gray, gray), -1, CV_AA);
				//}
			}
		}
	}
	imshow("Teste", borderpoints|points);
}

int main(int argc, char** argv) {


	image = imread("nissan.jpg", CV_LOAD_IMAGE_GRAYSCALE);

	srand(time(0));

	if (!image.data) {
		cout << "nao abriu nissan.jpg" << endl;
		exit(0);
	}

	width  = image.size().width;
	height = image.size().height;

	sprintf_s(lowTH_Track, "LowTH", lowTH_slider);
	sprintf_s(highTH_Track, "highTH", highTH_slider);
	sprintf_s(step_Track, "stepTH", step_slider);
	sprintf_s(jitter_Track, "jitterTH", jitter_slider);
	sprintf_s(raio_Track, "raioTH", raio_slider);
	sprintf_s(raio_Track, "raioTH", raio_edge);

	createTrackbar(lowTH_Track, "Canny", &lowTH_slider, lowTH_slider_max,
		on_trackbar_pontos);
	createTrackbar(highTH_Track, "Canny", &highTH_slider, highTH_slider_max,
		on_trackbar_pontos);
	createTrackbar(step_Track, "Canny", &step_slider, step_slider_max,
		on_trackbar_pontos);
	createTrackbar(jitter_Track, "Canny", &jitter_slider, jitter_slider_max,
		on_trackbar_pontos);
	createTrackbar(raio_Track, "Canny", &raio_slider, raio_slider_max,
		on_trackbar_pontos);
	createTrackbar(raioEdge_Track, "Canny", &raio_edge, raio_edge_max,
		on_trackbar_pontos);

	on_trackbar_pontos(lowTH_slider, 0);
	on_trackbar_pontos(highTH_slider, 0);
	on_trackbar_pontos(step_slider, 0);
	on_trackbar_pontos(jitter_slider, 0);
	on_trackbar_pontos(raio_slider, 0);
	on_trackbar_pontos(raio_edge, 0);

	namedWindow("Canny", 1);

	createTrackbar(lowTH_Track, "Canny", &lowTH_slider, lowTH_slider_max, on_trackbar_pontos);
	createTrackbar(highTH_Track, "Canny", &highTH_slider, highTH_slider_max, on_trackbar_pontos);
	createTrackbar(step_Track, "Canny", &step_slider, step_slider_max, on_trackbar_pontos);
	createTrackbar(jitter_Track, "Canny", &jitter_slider, jitter_slider_max, on_trackbar_pontos);
	createTrackbar(raio_Track, "Canny", &raio_slider, raio_slider_max, on_trackbar_pontos);
	createTrackbar(raioEdge_Track, "Canny", &raio_edge, raio_edge_max, on_trackbar_pontos);

	

	waitKey(0);
	return 0;
}
----

Para a compilação e execução foi usado o Visual Studio Comunity e os parâmetros de controle do filtro podem ser modificados usando o teclado durante a execução do programa

Usando como imagem de entrada o link:/OpenCV/imagens/nissan.jpg[*_Nissan_*]

image:/OpenCV/imagens/nissan.jpg[Nissan]

e executando o programa, obtemos a imagem link:/OpenCV/imagens/canny.png[*_Canny_*] do resultado do algoritmo canny

image:/OpenCV/imagens/canny.png[Canny]

a imagem link:/OpenCV/imagens/points.png[*_Points_*] resultado do pontilhismo

image:/OpenCV/imagens/hmorfico.png[Homomórfico]

e o resultado do progrma, que foi a 'soma' das duas imagens link:/OpenCV/imagens/cannypoints.png[*_CannyPoints_*] abaixo

image:/OpenCV/imagens/cannypoints.png[CannyPoints]

Para entender o código vamos observa-lo por parte:
O código inicia com as declarações dos elementos usados no programa

[source,cpp]
----
int step_slider = 3, step_slider_max = 10;
int jitter_slider = 3, jitter_slider_max = 20;
int raio_slider = 3, raio_slider_max = 5;
int raio_edge = 2, raio_edge_max = 5;
int lowTH_slider = 200, lowTH_slider_max = 200;
int highTH_slider = 600, highTH_slider_max = 600;
char step_Track[10], jitter_Track[10], raio_Track[10];
char raioEdge_Track[10], lowTH_Track[10], highTH_Track[10];

Mat image, points, border, borderpoints, fim;

vector<int> yrange, xrange;

int width, height, gray;
int x, y;
----

Após isso, definimos a função onde as operações serão executadas onde selecionamos pontos espaçados de 'step_slider' unidades e então emabaralhamos esses pontos. Depois, usando a variável 'jitter_slider', selecionamos pontos aleatórios ao redor do ponto selecionado na etapa anterior e desenhamos uma círculo de raio 'raio_slider' com a cor do pixel do centro desse círculo, e assim está pronta a imagem do pontilhismo.

[source,cpp]
----
Canny(image, border, lowTH_slider, highTH_slider);
if (step_slider < 2) step_slider = 1;
if (jitter_slider < 2) jitter_slider = 1;
if (raio_slider < 2) raio_slider = 1;
xrange.resize(height / step_slider);
yrange.resize(width / step_slider);

iota(xrange.begin(), xrange.end(), 0);
iota(yrange.begin(), yrange.end(), 0);

for (uint i = 0; i < xrange.size(); i++) {
	xrange[i] = xrange[i] * step_slider + step_slider / 2;
}

for (uint i = 0; i < yrange.size(); i++) {
	yrange[i] = yrange[i] * step_slider + step_slider / 2;
}

points = Mat(height, width, CV_8U, Scalar(255));

random_shuffle(xrange.begin(), xrange.end());
for (int i = 0; i < xrange.size(); i++) {
	random_shuffle(yrange.begin(), yrange.end());
	for (int j = 0; j < yrange.size(); j++) {
		x = xrange[i] + rand() % (2 * jitter_slider) - jitter_slider + 1;
		y = yrange[j] + rand() % (2 * jitter_slider) - jitter_slider + 1;
		if (x >= height) x = height - 1;
		if (y >= width) y = width - 1;
		if (x < 0) x = 0;
		if (y < 0) y = 0;
		gray = image.at<uchar>(x, y);
		circle(points, cv::Point(y, x), raio_slider, CV_RGB(gray, gray, gray), -1, CV_AA);
	}
}
----

Usando a detecção de bordas do canny que foi executada no início dessa função, desenhamos círculos de raio 'raio_edge' no pontos onde tem aresta e ao final 'somamos' as duas imagens numa operação de OR lógico.

[source,cpp]
----
borderpoints = Mat(height, width, CV_8U, Scalar(0));

for (int x = 0; x < height; x++) {
	for (int y = 0; y < width; y++) {
		if (border.at<uchar>(x, y) == 255) {
			//if (25 > (rand() % 100)) {
				gray = image.at<uchar>(x, y);
				circle(borderpoints, cv::Point(y, x), raio_edge, CV_RGB(gray, gray, gray), -1, CV_AA);
			//}
		}
	}
}
imshow("Teste", borderpoints|points);
----
